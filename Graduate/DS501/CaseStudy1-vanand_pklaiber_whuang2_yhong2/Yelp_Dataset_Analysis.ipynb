{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "yelp_dataset_group6.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqONK28_YCrr",
        "colab_type": "text"
      },
      "source": [
        "# Case Study 1 : Yelp Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkkUp0Y2YCrs",
        "colab_type": "text"
      },
      "source": [
        "**Required Readings:** \n",
        "* [Yelp Dataset Challenge](https://www.yelp.com/dataset_challenge) \n",
        "* Please download the Yelp dataset from the above webpage.\n",
        "\n",
        "**NOTE**\n",
        "* Please don't forget to save the notebook frequently when working in Jupyter Notebook, otherwise the changes you made can be lost.\n",
        "\n",
        "\n",
        "Here is an example of the data format. More details are included [here](https://www.yelp.com/dataset_challenge)\n",
        "\n",
        "## Business Objects\n",
        "\n",
        "Business objects contain basic information about local businesses. The fields are as follows:\n",
        "\n",
        "```json\n",
        "{\n",
        "  'type': 'business',\n",
        "  'business_id': (a unique identifier for this business),\n",
        "  'name': (the full business name),\n",
        "  'neighborhoods': (a list of neighborhood names, might be empty),\n",
        "  'full_address': (localized address),\n",
        "  'city': (city),\n",
        "  'state': (state),\n",
        "  'latitude': (latitude),\n",
        "  'longitude': (longitude),\n",
        "  'stars': (star rating, rounded to half-stars),\n",
        "  'review_count': (review count),\n",
        "  'photo_url': (photo url),\n",
        "  'categories': [(localized category names)]\n",
        "  'open': (is the business still open for business?),\n",
        "  'schools': (nearby universities),\n",
        "  'url': (yelp url)\n",
        "}\n",
        "```\n",
        "## Checkin Objects\n",
        "```json\n",
        "{\n",
        "    'type': 'checkin',\n",
        "    'business_id': (encrypted business id),\n",
        "    'checkin_info': {\n",
        "        '0-0': (number of checkins from 00:00 to 01:00 on all Sundays),\n",
        "        '1-0': (number of checkins from 01:00 to 02:00 on all Sundays),\n",
        "        ...\n",
        "        '14-4': (number of checkins from 14:00 to 15:00 on all Thursdays),\n",
        "        ...\n",
        "        '23-6': (number of checkins from 23:00 to 00:00 on all Saturdays)\n",
        "    }, # if there was no checkin for a hour-day block it will not be in the dict\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGPK4TxVYCru",
        "colab_type": "text"
      },
      "source": [
        "# Problem: pick a data science problem that you plan to solve using Yelp Data\n",
        "* The problem should be important and interesting, which has a potential impact in some area.\n",
        "* The problem should be solvable using yelp data and data science solutions.\n",
        "\n",
        "Please briefly describe in the following cell: what problem are you trying to solve? why this problem is important and interesting?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e21t8L1wYCrv",
        "colab_type": "text"
      },
      "source": [
        "The second aspect to consider the problem of the open or close status of a restaurant is from the rating star and all the attributes (e.g. food types, business time, parking availabilty and type, noiselevel, seat arrangement, decoration style, TV and WiFi availabilty, kids friendly, alcohol availability, food delivery, drive through, smoking allowing, disability friendly, pets friendly, music style, date of week operation, allergy identification, etc). The way to predict the restaurant business good or bad is very important and interesting since both restaurant owners and customers want to know what factors significantly influence a restaurant's profits. The restaurant owners may make usage of the discoveries to promote their businesses. Customers may better notice what kind of restaurants are popular and deserve to try."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdP4EFmLYCrw",
        "colab_type": "text"
      },
      "source": [
        "# Data Collection/Processing: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkiXBuH-YCrx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#----------------------------------------------\n",
        "# Your code starts here\n",
        "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
        "#   Please feel free to add more cells below this cell if necessary\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu0GbjX4YCr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read the business and the checkins json as pandas dataframe\n",
        "business = pd.read_json('yelp_dataset/business.json', lines=True)\n",
        "checkins = pd.read_json('yelp_dataset/checkin.json', lines=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlT4apBVYCr7",
        "colab_type": "code",
        "colab": {},
        "outputId": "ba09292c-2b9e-4300-fdae-3da312210498"
      },
      "source": [
        "business"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>business_id</th>\n",
              "      <th>name</th>\n",
              "      <th>address</th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>postal_code</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>stars</th>\n",
              "      <th>review_count</th>\n",
              "      <th>is_open</th>\n",
              "      <th>attributes</th>\n",
              "      <th>categories</th>\n",
              "      <th>hours</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1SWheh84yJXfytovILXOAQ</td>\n",
              "      <td>Arizona Biltmore Golf Club</td>\n",
              "      <td>2818 E Camino Acequia Drive</td>\n",
              "      <td>Phoenix</td>\n",
              "      <td>AZ</td>\n",
              "      <td>85016</td>\n",
              "      <td>33.522143</td>\n",
              "      <td>-112.018481</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>{'GoodForKids': 'False'}</td>\n",
              "      <td>Golf, Active Life</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>QXAEGFB4oINsVuTFxEYKFQ</td>\n",
              "      <td>Emerald Chinese Restaurant</td>\n",
              "      <td>30 Eglinton Avenue W</td>\n",
              "      <td>Mississauga</td>\n",
              "      <td>ON</td>\n",
              "      <td>L5R 3E7</td>\n",
              "      <td>43.605499</td>\n",
              "      <td>-79.652289</td>\n",
              "      <td>2.5</td>\n",
              "      <td>128</td>\n",
              "      <td>1</td>\n",
              "      <td>{'RestaurantsReservations': 'True', 'GoodForMe...</td>\n",
              "      <td>Specialty Food, Restaurants, Dim Sum, Imported...</td>\n",
              "      <td>{'Monday': '9:0-0:0', 'Tuesday': '9:0-0:0', 'W...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>gnKjwL_1w79qoiV3IC_xQQ</td>\n",
              "      <td>Musashi Japanese Restaurant</td>\n",
              "      <td>10110 Johnston Rd, Ste 15</td>\n",
              "      <td>Charlotte</td>\n",
              "      <td>NC</td>\n",
              "      <td>28210</td>\n",
              "      <td>35.092564</td>\n",
              "      <td>-80.859132</td>\n",
              "      <td>4.0</td>\n",
              "      <td>170</td>\n",
              "      <td>1</td>\n",
              "      <td>{'GoodForKids': 'True', 'NoiseLevel': 'u'avera...</td>\n",
              "      <td>Sushi Bars, Restaurants, Japanese</td>\n",
              "      <td>{'Monday': '17:30-21:30', 'Wednesday': '17:30-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>xvX2CttrVhyG2z1dFg_0xw</td>\n",
              "      <td>Farmers Insurance - Paul Lorenz</td>\n",
              "      <td>15655 W Roosevelt St, Ste 237</td>\n",
              "      <td>Goodyear</td>\n",
              "      <td>AZ</td>\n",
              "      <td>85338</td>\n",
              "      <td>33.455613</td>\n",
              "      <td>-112.395596</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>Insurance, Financial Services</td>\n",
              "      <td>{'Monday': '8:0-17:0', 'Tuesday': '8:0-17:0', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>HhyxOkGAM07SRYtlQ4wMFQ</td>\n",
              "      <td>Queen City Plumbing</td>\n",
              "      <td>4209 Stuart Andrew Blvd, Ste F</td>\n",
              "      <td>Charlotte</td>\n",
              "      <td>NC</td>\n",
              "      <td>28217</td>\n",
              "      <td>35.190012</td>\n",
              "      <td>-80.887223</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>{'BusinessAcceptsBitcoin': 'False', 'ByAppoint...</td>\n",
              "      <td>Plumbing, Shopping, Local Services, Home Servi...</td>\n",
              "      <td>{'Monday': '7:0-23:0', 'Tuesday': '7:0-23:0', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>192604</td>\n",
              "      <td>nqb4kWcOwp8bFxzfvaDpZQ</td>\n",
              "      <td>Sanderson Plumbing</td>\n",
              "      <td></td>\n",
              "      <td>North Las Vegas</td>\n",
              "      <td>NV</td>\n",
              "      <td>89032</td>\n",
              "      <td>36.213732</td>\n",
              "      <td>-115.177059</td>\n",
              "      <td>5.0</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>{'BusinessAcceptsCreditCards': 'True'}</td>\n",
              "      <td>Water Purification Services, Water Heater Inst...</td>\n",
              "      <td>{'Monday': '0:0-0:0', 'Tuesday': '0:0-0:0', 'W...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>192605</td>\n",
              "      <td>vY2nLU5K20Pee-FdG0br1g</td>\n",
              "      <td>Chapters</td>\n",
              "      <td>17440 Yonge Street</td>\n",
              "      <td>Newmarket</td>\n",
              "      <td>ON</td>\n",
              "      <td>L3Y 6Y9</td>\n",
              "      <td>44.052658</td>\n",
              "      <td>-79.481850</td>\n",
              "      <td>4.5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>{'RestaurantsPriceRange2': '2', 'BikeParking':...</td>\n",
              "      <td>Books, Mags, Music &amp; Video, Shopping</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>192606</td>\n",
              "      <td>MiEyUDKTjeci5TMfxVZPpg</td>\n",
              "      <td>Phoenix Pavers</td>\n",
              "      <td>21230 N 22nd St</td>\n",
              "      <td>Phoenix</td>\n",
              "      <td>AZ</td>\n",
              "      <td>85024</td>\n",
              "      <td>33.679992</td>\n",
              "      <td>-112.035569</td>\n",
              "      <td>4.5</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>{'BusinessAcceptsCreditCards': 'True', 'ByAppo...</td>\n",
              "      <td>Home Services, Contractors, Landscaping, Mason...</td>\n",
              "      <td>{'Monday': '7:0-15:0', 'Tuesday': '7:0-15:0', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>192607</td>\n",
              "      <td>zNMupayB2jEHVDOji8sxoQ</td>\n",
              "      <td>Beasley's Barber Shop</td>\n",
              "      <td>4406 E Main St</td>\n",
              "      <td>Mesa</td>\n",
              "      <td>AZ</td>\n",
              "      <td>85205</td>\n",
              "      <td>33.416137</td>\n",
              "      <td>-111.735743</td>\n",
              "      <td>4.5</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>{'RestaurantsPriceRange2': '1', 'BusinessAccep...</td>\n",
              "      <td>Beauty &amp; Spas, Barbers</td>\n",
              "      <td>{'Tuesday': '8:30-17:30', 'Wednesday': '8:30-1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>192608</td>\n",
              "      <td>c1f_VAX1KIK8-JoVhjbYOw</td>\n",
              "      <td>Oriental Relax</td>\n",
              "      <td>3735 S Las Vegas Blvd</td>\n",
              "      <td>Las Vegas</td>\n",
              "      <td>NV</td>\n",
              "      <td>89109</td>\n",
              "      <td>36.107267</td>\n",
              "      <td>-115.171920</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>{'BikeParking': 'False', 'RestaurantsPriceRang...</td>\n",
              "      <td>Massage, Beauty &amp; Spas</td>\n",
              "      <td>{'Monday': '10:0-0:0', 'Tuesday': '10:0-0:0', ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>192609 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   business_id                             name  \\\n",
              "0       1SWheh84yJXfytovILXOAQ       Arizona Biltmore Golf Club   \n",
              "1       QXAEGFB4oINsVuTFxEYKFQ       Emerald Chinese Restaurant   \n",
              "2       gnKjwL_1w79qoiV3IC_xQQ      Musashi Japanese Restaurant   \n",
              "3       xvX2CttrVhyG2z1dFg_0xw  Farmers Insurance - Paul Lorenz   \n",
              "4       HhyxOkGAM07SRYtlQ4wMFQ              Queen City Plumbing   \n",
              "...                        ...                              ...   \n",
              "192604  nqb4kWcOwp8bFxzfvaDpZQ               Sanderson Plumbing   \n",
              "192605  vY2nLU5K20Pee-FdG0br1g                         Chapters   \n",
              "192606  MiEyUDKTjeci5TMfxVZPpg                   Phoenix Pavers   \n",
              "192607  zNMupayB2jEHVDOji8sxoQ            Beasley's Barber Shop   \n",
              "192608  c1f_VAX1KIK8-JoVhjbYOw                   Oriental Relax   \n",
              "\n",
              "                               address             city state postal_code  \\\n",
              "0          2818 E Camino Acequia Drive          Phoenix    AZ       85016   \n",
              "1                 30 Eglinton Avenue W      Mississauga    ON     L5R 3E7   \n",
              "2            10110 Johnston Rd, Ste 15        Charlotte    NC       28210   \n",
              "3        15655 W Roosevelt St, Ste 237         Goodyear    AZ       85338   \n",
              "4       4209 Stuart Andrew Blvd, Ste F        Charlotte    NC       28217   \n",
              "...                                ...              ...   ...         ...   \n",
              "192604                                  North Las Vegas    NV       89032   \n",
              "192605              17440 Yonge Street        Newmarket    ON     L3Y 6Y9   \n",
              "192606                 21230 N 22nd St          Phoenix    AZ       85024   \n",
              "192607                  4406 E Main St             Mesa    AZ       85205   \n",
              "192608           3735 S Las Vegas Blvd        Las Vegas    NV       89109   \n",
              "\n",
              "         latitude   longitude  stars  review_count  is_open  \\\n",
              "0       33.522143 -112.018481    3.0             5        0   \n",
              "1       43.605499  -79.652289    2.5           128        1   \n",
              "2       35.092564  -80.859132    4.0           170        1   \n",
              "3       33.455613 -112.395596    5.0             3        1   \n",
              "4       35.190012  -80.887223    4.0             4        1   \n",
              "...           ...         ...    ...           ...      ...   \n",
              "192604  36.213732 -115.177059    5.0             9        1   \n",
              "192605  44.052658  -79.481850    4.5             3        1   \n",
              "192606  33.679992 -112.035569    4.5            14        1   \n",
              "192607  33.416137 -111.735743    4.5            15        1   \n",
              "192608  36.107267 -115.171920    4.0             3        0   \n",
              "\n",
              "                                               attributes  \\\n",
              "0                                {'GoodForKids': 'False'}   \n",
              "1       {'RestaurantsReservations': 'True', 'GoodForMe...   \n",
              "2       {'GoodForKids': 'True', 'NoiseLevel': 'u'avera...   \n",
              "3                                                    None   \n",
              "4       {'BusinessAcceptsBitcoin': 'False', 'ByAppoint...   \n",
              "...                                                   ...   \n",
              "192604             {'BusinessAcceptsCreditCards': 'True'}   \n",
              "192605  {'RestaurantsPriceRange2': '2', 'BikeParking':...   \n",
              "192606  {'BusinessAcceptsCreditCards': 'True', 'ByAppo...   \n",
              "192607  {'RestaurantsPriceRange2': '1', 'BusinessAccep...   \n",
              "192608  {'BikeParking': 'False', 'RestaurantsPriceRang...   \n",
              "\n",
              "                                               categories  \\\n",
              "0                                       Golf, Active Life   \n",
              "1       Specialty Food, Restaurants, Dim Sum, Imported...   \n",
              "2                       Sushi Bars, Restaurants, Japanese   \n",
              "3                           Insurance, Financial Services   \n",
              "4       Plumbing, Shopping, Local Services, Home Servi...   \n",
              "...                                                   ...   \n",
              "192604  Water Purification Services, Water Heater Inst...   \n",
              "192605               Books, Mags, Music & Video, Shopping   \n",
              "192606  Home Services, Contractors, Landscaping, Mason...   \n",
              "192607                             Beauty & Spas, Barbers   \n",
              "192608                             Massage, Beauty & Spas   \n",
              "\n",
              "                                                    hours  \n",
              "0                                                    None  \n",
              "1       {'Monday': '9:0-0:0', 'Tuesday': '9:0-0:0', 'W...  \n",
              "2       {'Monday': '17:30-21:30', 'Wednesday': '17:30-...  \n",
              "3       {'Monday': '8:0-17:0', 'Tuesday': '8:0-17:0', ...  \n",
              "4       {'Monday': '7:0-23:0', 'Tuesday': '7:0-23:0', ...  \n",
              "...                                                   ...  \n",
              "192604  {'Monday': '0:0-0:0', 'Tuesday': '0:0-0:0', 'W...  \n",
              "192605                                               None  \n",
              "192606  {'Monday': '7:0-15:0', 'Tuesday': '7:0-15:0', ...  \n",
              "192607  {'Tuesday': '8:30-17:30', 'Wednesday': '8:30-1...  \n",
              "192608  {'Monday': '10:0-0:0', 'Tuesday': '10:0-0:0', ...  \n",
              "\n",
              "[192609 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ztTWtMUYCsE",
        "colab_type": "code",
        "colab": {},
        "outputId": "39a8edeb-2e99-45c2-e0dc-68c0b6cda0a0"
      },
      "source": [
        "checkins"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>business_id</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>--1UhMGODdWsrMastO9DZw</td>\n",
              "      <td>2016-04-26 19:49:16, 2016-08-30 18:36:57, 2016...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>--6MefnULPED_I942VcFNA</td>\n",
              "      <td>2011-06-04 18:22:23, 2011-07-23 23:51:33, 2012...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>--7zmmkVg-IMGaXbuVd0SQ</td>\n",
              "      <td>2014-12-29 19:25:50, 2015-01-17 01:49:14, 2015...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>--8LPVSo5i0Oo61X01sV9A</td>\n",
              "      <td>2016-07-08 16:43:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>--9QQLMTbFzLJ_oT-ON3Xw</td>\n",
              "      <td>2010-06-26 17:39:07, 2010-08-01 20:06:21, 2010...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>161945</td>\n",
              "      <td>zzvlwkcNR1CCqOPXwuvz2A</td>\n",
              "      <td>2017-05-06 20:05:15, 2017-05-12 22:37:03, 2017...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>161946</td>\n",
              "      <td>zzwaS0xn1MVEPEf0hNLjew</td>\n",
              "      <td>2010-02-16 02:09:56, 2010-07-05 05:40:48, 2010...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>161947</td>\n",
              "      <td>zzwhN7x37nyjP0ZM8oiHmw</td>\n",
              "      <td>2016-03-06 13:27:02, 2016-03-09 00:41:53, 2016...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>161948</td>\n",
              "      <td>zzwicjPC9g246MK2M1ZFBA</td>\n",
              "      <td>2012-09-22 00:26:15, 2012-09-23 20:12:00, 2012...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>161949</td>\n",
              "      <td>zzzaIBwimxVej4tY6qFOUQ</td>\n",
              "      <td>2012-10-12 16:26:35, 2012-10-19 19:31:14, 2012...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>161950 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   business_id  \\\n",
              "0       --1UhMGODdWsrMastO9DZw   \n",
              "1       --6MefnULPED_I942VcFNA   \n",
              "2       --7zmmkVg-IMGaXbuVd0SQ   \n",
              "3       --8LPVSo5i0Oo61X01sV9A   \n",
              "4       --9QQLMTbFzLJ_oT-ON3Xw   \n",
              "...                        ...   \n",
              "161945  zzvlwkcNR1CCqOPXwuvz2A   \n",
              "161946  zzwaS0xn1MVEPEf0hNLjew   \n",
              "161947  zzwhN7x37nyjP0ZM8oiHmw   \n",
              "161948  zzwicjPC9g246MK2M1ZFBA   \n",
              "161949  zzzaIBwimxVej4tY6qFOUQ   \n",
              "\n",
              "                                                     date  \n",
              "0       2016-04-26 19:49:16, 2016-08-30 18:36:57, 2016...  \n",
              "1       2011-06-04 18:22:23, 2011-07-23 23:51:33, 2012...  \n",
              "2       2014-12-29 19:25:50, 2015-01-17 01:49:14, 2015...  \n",
              "3                                     2016-07-08 16:43:30  \n",
              "4       2010-06-26 17:39:07, 2010-08-01 20:06:21, 2010...  \n",
              "...                                                   ...  \n",
              "161945  2017-05-06 20:05:15, 2017-05-12 22:37:03, 2017...  \n",
              "161946  2010-02-16 02:09:56, 2010-07-05 05:40:48, 2010...  \n",
              "161947  2016-03-06 13:27:02, 2016-03-09 00:41:53, 2016...  \n",
              "161948  2012-09-22 00:26:15, 2012-09-23 20:12:00, 2012...  \n",
              "161949  2012-10-12 16:26:35, 2012-10-19 19:31:14, 2012...  \n",
              "\n",
              "[161950 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zW8Z1xLsYCsM",
        "colab_type": "text"
      },
      "source": [
        "# Data Exploration: Exploring the Yelp Dataset\n",
        "\n",
        "**(1) Finding the most popular business categories:** \n",
        "* print the top 10 most popular business categories in the dataset and their counts (i.e., how many business objects in each category). Here we say a category is \"popular\" if there are many business objects in this category (such as 'restaurants')."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3WDyWRPYCsM",
        "colab_type": "code",
        "colab": {},
        "outputId": "0d201066-5e63-46a6-fda9-c3361d587430"
      },
      "source": [
        "# Your code starts here\n",
        "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
        "#   Please feel free to add more cells below this cell if necessary\n",
        "\n",
        "# split the categories column, so that we can group and count the containing objects\n",
        "business[\"categories\"]= business[\"categories\"].str.split(\",\", expand = True) \n",
        "\n",
        "# group the categories unique and count their appearances\n",
        "categories = business.groupby('categories')['business_id'].nunique()\n",
        "\n",
        "# sort the appearances descending\n",
        "categories = categories.sort_values(ascending=False)\n",
        "\n",
        "# only show the first 10 rows\n",
        "categories.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "categories\n",
              "Restaurants         17948\n",
              "Food                 8023\n",
              "Shopping             7791\n",
              "Beauty & Spas        5832\n",
              "Home Services        5267\n",
              "Health & Medical     4570\n",
              "Automotive           4130\n",
              "Local Services       3413\n",
              "Nightlife            2713\n",
              "Active Life          2319\n",
              "Name: business_id, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CTauZ3RYCsW",
        "colab_type": "text"
      },
      "source": [
        "** (2) Find the most popular business objects** \n",
        "* print the top 10 most popular business objects in the dataset and their counts (i.e., how many checkins in total for each business object).  Here we say a business object is \"popular\" if the business object attracts a large number of checkins from the users."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SCLRS2qYCsX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your code starts here\n",
        "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
        "#   Please feel free to add more cells below this cell if necessary\n",
        "\n",
        "# split the date column, so that we can group and count the containing objects\n",
        "checkins['date'] = checkins[\"date\"].str.split(\",\")\n",
        "\n",
        "# count the amount of dates in each row to get the total amount of check ins\n",
        "checkins['num_checkins'] = checkins.apply(lambda row: len(row.date), axis = 1)\n",
        "\n",
        "# sort the amount of checkins descending\n",
        "checkins = checkins.sort_values(by=['num_checkins'], ascending=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AJatInPYCsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "most_checkins = checkins.head(10).copy()\n",
        "\n",
        "# search for the business name with the corresponding business_id as key\n",
        "most_checkins['name'] = most_checkins.apply(lambda row: business.loc[business['business_id'] == row['business_id']].name.values[0], axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aUr1yW9YCsk",
        "colab_type": "code",
        "colab": {},
        "outputId": "68f8cf11-a766-4609-8039-41990dcbd7bb"
      },
      "source": [
        "most_checkins"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>business_id</th>\n",
              "      <th>date</th>\n",
              "      <th>num_checkins</th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>42142</td>\n",
              "      <td>FaHADZARwnY4yvlvpnsfGA</td>\n",
              "      <td>[2010-01-15 22:59:12,  2010-01-16 02:39:11,  2...</td>\n",
              "      <td>143061</td>\n",
              "      <td>McCarran International Airport</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52735</td>\n",
              "      <td>JmI9nslLD7KZqRr__Bg6NQ</td>\n",
              "      <td>[2010-01-16 04:30:54,  2010-01-16 13:47:11,  2...</td>\n",
              "      <td>123126</td>\n",
              "      <td>Phoenix Sky Harbor International Airport</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>157953</td>\n",
              "      <td>yQab5dxZzgBLTEHCw9V7_w</td>\n",
              "      <td>[2010-01-17 18:28:10,  2010-01-23 18:18:38,  2...</td>\n",
              "      <td>54787</td>\n",
              "      <td>Charlotte Douglas International Airport</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15955</td>\n",
              "      <td>5LNZ67Yw9RD6nf4_UhXOjw</td>\n",
              "      <td>[2010-07-20 13:11:27,  2010-11-08 16:56:23,  2...</td>\n",
              "      <td>46384</td>\n",
              "      <td>The Cosmopolitan of Las Vegas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49667</td>\n",
              "      <td>IZivKqtHyz4-ts8KsnvMrA</td>\n",
              "      <td>[2014-07-03 05:26:09,  2014-07-04 02:08:10,  2...</td>\n",
              "      <td>38277</td>\n",
              "      <td>Kung Fu Tea</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74469</td>\n",
              "      <td>SMPbvZLSMMb7KU76YNYMGg</td>\n",
              "      <td>[2010-01-17 06:14:44,  2010-01-17 19:51:31,  2...</td>\n",
              "      <td>34353</td>\n",
              "      <td>ARIA Resort &amp; Casino</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86134</td>\n",
              "      <td>Wxxvi3LZbHNIDwJ-ZimtnA</td>\n",
              "      <td>[2010-01-16 18:05:13,  2010-01-24 10:27:06,  2...</td>\n",
              "      <td>32343</td>\n",
              "      <td>The Venetian Las Vegas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130714</td>\n",
              "      <td>na4Th5DrNauOv-c43QQFvA</td>\n",
              "      <td>[2010-01-17 02:56:04,  2010-01-23 22:18:47,  2...</td>\n",
              "      <td>31185</td>\n",
              "      <td>Bellagio Hotel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83644</td>\n",
              "      <td>VyjyHoBg3KC5BSFRlD0ZPQ</td>\n",
              "      <td>[2010-01-17 03:59:05,  2010-01-18 02:23:32,  2...</td>\n",
              "      <td>30782</td>\n",
              "      <td>Caesars Palace Las Vegas Hotel &amp; Casino</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39989</td>\n",
              "      <td>El4FC8jcawUVgw_0EIcbaQ</td>\n",
              "      <td>[2010-01-24 03:48:14,  2010-01-24 05:50:43,  2...</td>\n",
              "      <td>30098</td>\n",
              "      <td>MGM Grand Hotel</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   business_id  \\\n",
              "42142   FaHADZARwnY4yvlvpnsfGA   \n",
              "52735   JmI9nslLD7KZqRr__Bg6NQ   \n",
              "157953  yQab5dxZzgBLTEHCw9V7_w   \n",
              "15955   5LNZ67Yw9RD6nf4_UhXOjw   \n",
              "49667   IZivKqtHyz4-ts8KsnvMrA   \n",
              "74469   SMPbvZLSMMb7KU76YNYMGg   \n",
              "86134   Wxxvi3LZbHNIDwJ-ZimtnA   \n",
              "130714  na4Th5DrNauOv-c43QQFvA   \n",
              "83644   VyjyHoBg3KC5BSFRlD0ZPQ   \n",
              "39989   El4FC8jcawUVgw_0EIcbaQ   \n",
              "\n",
              "                                                     date  num_checkins  \\\n",
              "42142   [2010-01-15 22:59:12,  2010-01-16 02:39:11,  2...        143061   \n",
              "52735   [2010-01-16 04:30:54,  2010-01-16 13:47:11,  2...        123126   \n",
              "157953  [2010-01-17 18:28:10,  2010-01-23 18:18:38,  2...         54787   \n",
              "15955   [2010-07-20 13:11:27,  2010-11-08 16:56:23,  2...         46384   \n",
              "49667   [2014-07-03 05:26:09,  2014-07-04 02:08:10,  2...         38277   \n",
              "74469   [2010-01-17 06:14:44,  2010-01-17 19:51:31,  2...         34353   \n",
              "86134   [2010-01-16 18:05:13,  2010-01-24 10:27:06,  2...         32343   \n",
              "130714  [2010-01-17 02:56:04,  2010-01-23 22:18:47,  2...         31185   \n",
              "83644   [2010-01-17 03:59:05,  2010-01-18 02:23:32,  2...         30782   \n",
              "39989   [2010-01-24 03:48:14,  2010-01-24 05:50:43,  2...         30098   \n",
              "\n",
              "                                            name  \n",
              "42142             McCarran International Airport  \n",
              "52735   Phoenix Sky Harbor International Airport  \n",
              "157953   Charlotte Douglas International Airport  \n",
              "15955              The Cosmopolitan of Las Vegas  \n",
              "49667                                Kung Fu Tea  \n",
              "74469                       ARIA Resort & Casino  \n",
              "86134                     The Venetian Las Vegas  \n",
              "130714                            Bellagio Hotel  \n",
              "83644    Caesars Palace Las Vegas Hotel & Casino  \n",
              "39989                            MGM Grand Hotel  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amlFvu6kYCso",
        "colab_type": "text"
      },
      "source": [
        "# The Solution: implement a data science solution to the problem you are trying to solve."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTlTvY3FYCsq",
        "colab_type": "text"
      },
      "source": [
        "Briefly describe the idea of your solution to the problem in the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPSC_bTtZblt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The problem we are trying to solve is:\n",
        "# We want to figure out the relationship between some given factors that may impact a business to terminate and then communicate that reasoning to Yelp so that struggling businesses have a chance to survive in the market.\n",
        "# We will be investigating the restaurant business category because it the number one most occurring category out of the whole Yelp dataset."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mP5qahxAYCsq",
        "colab_type": "text"
      },
      "source": [
        "For the second part of predicting restaurants are whether open or permenantly closed, we primarily apply four steps: (a) feature selection (b) Missing value handling (c) model selection (d) evaluation. For feature selection, we consider features from initilly 90 narrow down to 41 features; for missing value handling, we tried mean and extreme value; for model selection we focus on logstic regression and XGBoost; for evaluation we use cross validation, confusion matrix, precision, recall, and F1 score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-UhoBhuZdVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Our solution is:\n",
        "# Collect data of the Closed Business regarding its ratings and customer reviews\n",
        "# Develop a Review Attitude Model and Rating Model to analyze how various factors (ratings and reviews in this case) impact the business closure"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uS4dYtJqYCsr",
        "colab_type": "text"
      },
      "source": [
        "Write codes to implement the solution in python:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMNmDfp-YCsr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your code starts here\n",
        "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
        "#   Please feel free to add more cells below this cell if necessary\n",
        "\n",
        "# load business dataframe\n",
        "data_df = pd.read_json('yelp_dataset/business.json', lines=True)\n",
        "\n",
        "#restaurant selection and review number threshold \n",
        "## pick only restaurants\n",
        "drop_array = []\n",
        "for index, row in data_df.iterrows():\n",
        "    if row['categories'] is None:\n",
        "        drop_array.append(index)\n",
        "        continue\n",
        "    cat = row['categories'].split(', ')\n",
        "    if not 'Restaurants' in cat:\n",
        "        drop_array.append(index)\n",
        "data_df = data_df.drop(data_df.index[drop_array])\n",
        "\n",
        "## review number threshold >= 50\n",
        "data_df = data_df[data_df['review_count'] >= 50]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqI0NY9dYCsv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#(a) feature selection\n",
        "delete_column = ['index', 'business_id', 'Unnamed: 0', 'is_open']\n",
        "X = data_df.drop(delete_column, axis=1)\n",
        "y = data_df['is_open'].values\n",
        "\n",
        "## remove columns full of nan\n",
        "mean_X = X\n",
        "sum(mean_X.isna().sum() == mean_X.shape[0])\n",
        "delcol = []\n",
        "for column in mean_X:\n",
        "    if mean_X[column].isna().sum() == mean_X.shape[0]:\n",
        "        delcol.append(column)\n",
        "print(delcol)\n",
        "mean_X = mean_X.drop(delcol, axis = 1)\n",
        "print(mean_X.shape)\n",
        "print(X.shape)\n",
        "\n",
        "## delete #nan > 10000\n",
        "proportion_X = mean_X\n",
        "del_column = []\n",
        "for column in proportion_X:\n",
        "    if proportion_X[column].isna().sum() > 10000:\n",
        "        del_column.append(column)\n",
        "proportion_X = proportion_X.drop(del_column, axis=1)\n",
        "proportion_X.shape #41 columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXwddtawYCsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#(b) missing value handling\n",
        "proportion_X_1 = proportion_X\n",
        "proportion_X_2 = proportion_X\n",
        "proportion_X_3 = proportion_X\n",
        "## replace nan with mean value -- method 1\n",
        "for column in proportion_X_1:\n",
        "    tempsum = proportion_X_1[column].sum()\n",
        "    tempcount = proportion_X_1.shape[0] - proportion_X_1[column].isna().sum()\n",
        "    if tempcount==0:\n",
        "        continue\n",
        "    meanvalue = tempsum / tempcount\n",
        "    proportion_X_1[column] = proportion_X_1[column].fillna(meanvalue)\n",
        "\n",
        "## replace nan with -99999 -- method 2\n",
        "proportion_X_2 = proportion_X_2.fillna(-9999)\n",
        "\n",
        "## replace nan with 0 -- method 3\n",
        "proportion_X_3 = proportion_X_3.fillna(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqq-84lZYCs2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#(c) model selection\n",
        "input_set = proportion_X_3\n",
        "output_set = y\n",
        "input_set = np.array(input_set)\n",
        "kf = KFold(n_splits=2)\n",
        "kf.get_n_splits(input_set)\n",
        "for train_index, test_index in kf.split(input_set):\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_train, X_test = input_set[train_index], input_set[test_index]\n",
        "    y_train, y_test = output_set[train_index], output_set[test_index]\n",
        "\n",
        "## logistic \n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "\n",
        "##XGBOOST\n",
        "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "y_pred_xgb = xgb_model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPu4BiIfYCs8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#(d) evalution\n",
        "print(confusion_matrix(y_test, y_pred_xgb))\n",
        "print(classification_report(y_test, y_pred_xgb))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4SioCvaYCtC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your code starts here\n",
        "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
        "#   Please feel free to add more cells below this cell if necessary\n",
        "import json\n",
        "\n",
        "business = \"yelp_dataset/business.json\"\n",
        "yelpdata = \"\"\n",
        "\n",
        "with open(business, 'r') as file:\n",
        "    yelpdata = file.read()\n",
        "# print(json.dumps(yelpdata, separators=('\\n', ':')))\n",
        "str_close_business = yelpdata.split(\"\\n\")\n",
        "\n",
        "close_business = []\n",
        "\n",
        "for obj in str_close_business:\n",
        "    if obj != \"\":\n",
        "        close_business.append(json.loads(obj))\n",
        "        \n",
        "print('Collect data from: ', business, ' Complete !!!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ew6kGJgWYCtF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "close_restaurant = []\n",
        "res_review = dict()\n",
        "\n",
        "for c in close_business:\n",
        "    number = 0\n",
        "    business_id = c['business_id']\n",
        "    business_name = c['name']\n",
        "    b_categories = str(c['categories']).split(\", \")\n",
        "    if 'is_open' in c and c['is_open'] == 0 and 'Restaurants' in b_categories:\n",
        "        close_restaurant.append(business_id)\n",
        "        res_review[business_id] = 0\n",
        "print(len(close_restaurant))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5Jl6EuzYCtJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review = \"yelp_dataset/review.json\"\n",
        "reviewdata = \"\"\n",
        "\n",
        "with open(review, 'r') as file:\n",
        "    sf = file.readline()\n",
        "    while(sf != \"\"):\n",
        "        onereview = json.loads(sf)\n",
        "        bID = onereview['business_id']\n",
        "        if bID in close_restaurant:  # only reviews from closed business!\n",
        "            res_review[bID] += 1\n",
        "        sf = file.readline()\n",
        "\n",
        "print('Collect data from: ', review, ' Complete !!!')\n",
        "print(len(res_review))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBCw9BCfYCtM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import operator\n",
        "print(len(res_review))\n",
        "sorted_review = sorted(res_review.items(), key=operator.itemgetter(1), reverse=True)\n",
        "review_ten = dict()\n",
        "\n",
        "count = 10\n",
        "for key, value in sorted_review:\n",
        "    if count < 1:\n",
        "        break\n",
        "    for c in close_business:\n",
        "        if key in c['business_id']:\n",
        "            review_ten[key] = (c['name'], value, [])\n",
        "            print(key, \":  (\", c['name'], \":\\t\", value, \")\")\n",
        "            break\n",
        "    count -= 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cOHUAQjYCtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review = \"yelp_dataset/review.json\"\n",
        "idList = list(review_ten.keys())\n",
        "\n",
        "with open(review, 'r') as file:\n",
        "    sf = file.readline()\n",
        "    while(sf != \"\"):\n",
        "        onereview = json.loads(sf)\n",
        "        bID = onereview['business_id']\n",
        "        if bID in idList:  # only reviews from closed business!\n",
        "            review_ten[bID][2].append(onereview['text'])\n",
        "        sf = file.readline()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb7Ay0jVYCtS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#######\n",
        "#\n",
        "#  Apply the NaiveBayesModel to analysis the top 10 closed restaurants. \n",
        "#\n",
        "#######\n",
        "\n",
        "def NaiveBayesModel(review_list):\n",
        "    neg = 0\n",
        "    pos = 0\n",
        "    total = len(review_list)\n",
        "    for sentence in review_list:\n",
        "        words = sentence.lower().split(' ')\n",
        "        negSum = 0\n",
        "        posSum = 0\n",
        "        for word in words:\n",
        "            classResult = classifier.classify(word_feats(word))\n",
        "            if classResult == 'neg':\n",
        "                negSum += 1\n",
        "            elif classResult == 'pos':\n",
        "                posSum += 1\n",
        "        neg += float(negSum)/len(words)\n",
        "        pos += float(posSum)/len(words)\n",
        "    \n",
        "    return (float(pos)/total, float(neg)/total, 1 - float(pos)/total - float(neg)/total)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VogAY2mLYCtU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_results = dict()\n",
        "\n",
        "for key, value in review_ten.items():\n",
        "    result = NaiveBayesModel(value[2])\n",
        "    nb_results[key] = result\n",
        "    print(value[0], result[0], result[1], result[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-wej3CmYCtX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here is the NaiveBayesClassifier Model to analyze the review with positive, nagative and neutral.\n",
        "from random import shuffle\n",
        "import nltk.classify.util\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "from nltk.corpus import names\n",
        "import string\n",
        "\n",
        "def word_feats(words):\n",
        "    return dict([(word, True) for word in words])\n",
        "\n",
        "positive_vocab = ['thanks','awesome', 'outstanding', 'fantastic', 'terrific', 'good', 'nice', 'great', 'super', 'wonderful', 'achievable', 'Delicious','tasty','again']\n",
        "negative_vocab = ['bad', 'terrible', 'useless', 'hate', ':(', 'not', 'no', 'aweful', 'sad', 'accuse', 'aggressive' , 'annoy']\n",
        "neutral_vocab = ['when','where','who','why','what','which','is','was','do','did','how','were']\n",
        "\n",
        "# input the positive words list\n",
        "with open('yelp_dataset/positive.txt', 'r') as file:  \n",
        "    sf = file.readline()\n",
        "    while(sf != \"\"):\n",
        "        positive_vocab.append(sf.rstrip())\n",
        "        sf = file.readline()\n",
        "\n",
        "# input the negative words list\n",
        "with open('yelp_dataset/negative.txt', 'r') as file:\n",
        "    sf = file.readline()\n",
        "    while(sf != \"\"):\n",
        "        negative_vocab.append(sf.rstrip())\n",
        "        sf = file.readline()\n",
        "        \n",
        "positive_features = [(word_feats(pos), 'pos') for pos in positive_vocab]\n",
        "negative_features = [(word_feats(neg), 'neg') for neg in negative_vocab]\n",
        "neutral_features = [(word_feats(neu), 'neu') for neu in neutral_vocab]\n",
        "\n",
        "# shuffle to make sure the length of negtive features is the same as the positive features\n",
        "shuffle(negative_features)\n",
        "negative_features = negative_features[0:len(positive_features)]\n",
        "\n",
        "train_set = negative_features + positive_features + neutral_features\n",
        " \n",
        "classifier = NaiveBayesClassifier.train(train_set) \n",
        "\n",
        "# Predict\n",
        "neg = 0\n",
        "pos = 0\n",
        "sentence = \"Delicious! Ordered through Grubhub and it came within an hour on a Sunday night. It was hot still. We ordered a Hawaiian pizza and it was delicious. Perfect amount of cheese and sauce was sweet. The dough was super tasty- I usually skip the crust but this crust was too good! The fries were good but the to-go box should have some vent holes in it so they don't get too soggy. Great pizza place. I'll be ordering again!\"\n",
        "words = sentence.split(' ')\n",
        "for word in words:\n",
        "    classResult = classifier.classify(word_feats(word))\n",
        "    if classResult == 'neg':\n",
        "        neg = neg + 1\n",
        "    elif classResult == 'pos':\n",
        "        pos = pos + 1\n",
        "\n",
        "print('Positive: ' + str(float(pos)/len(words)))\n",
        "print('Negative: ' + str(float(neg)/len(words)))\n",
        "print('Neutral: ' + str(1 - float(pos)/len(words) - float(neg)/len(words)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUgWxdOVYCta",
        "colab_type": "text"
      },
      "source": [
        "# Results: summarize and visualize the results discovered from the analysis\n",
        "\n",
        "Please use figures, tables, or videos to communicate the results with the audience.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02_gc3WIYCtb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your code starts here\n",
        "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
        "#   Please feel free to add more cells below this cell if necessary\n",
        "\n",
        "#################### results for the second aspect ##################\n",
        "## logistic \n",
        "#[[ 758  797]\n",
        "# [ 318 6967]]\n",
        "#              precision    recall  f1-score   support\n",
        "#\n",
        "#          -1       0.70      0.49      0.58      1555\n",
        "#           1       0.90      0.96      0.93      7285\n",
        "#\n",
        "\n",
        "\n",
        "##XGBoost\n",
        "#[[ 989  566]\n",
        "# [ 247 7038]]\n",
        "#              precision    recall  f1-score   support\n",
        "#\n",
        "#          -1       0.80      0.63      0.70      1555\n",
        "#           1       0.92      0.97      0.94      7285\n",
        "#\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Bo_OQB-YCte",
        "colab_type": "text"
      },
      "source": [
        "*-----------------\n",
        "# Done\n",
        "\n",
        "All set! \n",
        "\n",
        "**What do you need to submit?**\n",
        "\n",
        "* **Notebook File**: Save this Jupyter notebook, and find the notebook file in your folder (for example, \"filename.ipynb\"). This is the file you need to submit. Please make sure all the plotted tables and figures are in the notebook. If you used \"jupyter notebook --pylab=inline\" to open the notebook, all the figures and tables should have shown up in the notebook.\n",
        "\n",
        "* **PPT Slides**: please prepare PPT slides (for 7 minutes' talk) to present about the case study . Each team present their case studies in class for 7 minutes.\n",
        "\n",
        "Please compress all the files in a zipped file.\n",
        "\n",
        "\n",
        "**How to submit:**\n",
        "\n",
        "        Please submit through Canvas, in the Assignment \"Case Study 1\".\n",
        "        \n",
        "**Note: Each team only needs to submit one submission in Canvas**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VClBJ8TRYCte",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Peer-Review Grading Template:\n",
        "\n",
        "**Total Points: (100 points)** Please don't worry about the absolute scores, we will rescale the final grading according to the performance of all teams in the class.\n",
        "\n",
        "Please add an \"**X**\" mark in front of your rating: \n",
        "\n",
        "For example:\n",
        "\n",
        "*2: bad*\n",
        "          \n",
        "**X** *3: good*\n",
        "    \n",
        "*4: perfect*\n",
        "\n",
        "\n",
        "    ---------------------------------\n",
        "    The Problem: \n",
        "    ---------------------------------\n",
        "    \n",
        "    1. (10 points) how well did the team describe the problem they are trying to solve using the data? \n",
        "       0: not clear\n",
        "       2: I can barely understand the problem\n",
        "       4: okay, can be improved\n",
        "       6: good, but can be improved\n",
        "       8: very good\n",
        "       10: crystal clear\n",
        "    \n",
        "    2. (10 points) do you think the problem is important or has a potential impact?\n",
        "        0: not important at all\n",
        "        2: not sure if it is important\n",
        "        4: seems important, but not clear\n",
        "        6: interesting problem\n",
        "        8: an important problem, which I want to know the answer myself\n",
        "       10: very important, I would be happy invest money on a project like this.\n",
        "    \n",
        "    ----------------------------------\n",
        "    Data Collection and Processing:\n",
        "    ----------------------------------\n",
        "    \n",
        "    3. (10 points) Do you think the data collected/processed are relevant and sufficient for solving the above problem? \n",
        "       0: not clear\n",
        "       2: I can barely understand what data they are trying to collect/process\n",
        "       4: I can barely understand why the data is relevant to the problem\n",
        "       6: the data are relevant to the problem, but better data can be collected\n",
        "       8: the data collected are relevant and at a proper scale\n",
        "      10: the data are properly collected and they are sufficient\n",
        "\n",
        "    -----------------------------------\n",
        "    Data Exploration:\n",
        "    -----------------------------------\n",
        "    4. How well did the team solve the following task:\n",
        "    \n",
        "    (1) Finding the most popular business categories (5 points):\n",
        "       0: missing answer\n",
        "       1: okay, but with major problems\n",
        "       3: good, but with minor problems\n",
        "       5: perfect\n",
        "    \n",
        "    (2) Find the most popular business objects (5 points)\n",
        "       0: missing answer\n",
        "       1: okay, but with major problems\n",
        "       3: good, but with minor problems\n",
        "       5: perfect\n",
        "    \n",
        "    -----------------------------------\n",
        "    The Solution\n",
        "    -----------------------------------\n",
        "    5.  how well did the team describe the solution they used to solve the problem? (10 points)\n",
        "       0: not clear\n",
        "       2: I can barely understand\n",
        "       4: okay, can be improved\n",
        "       6: good, but can be improved\n",
        "       8: very good\n",
        "       10: crystal clear\n",
        "       \n",
        "    6. how well is the solution in solving the problem? (10 points)\n",
        "       0: not relevant\n",
        "       2: barely relevant to the problem\n",
        "       4: okay solution, but there is an easier solution.\n",
        "       6: good, but can be improved\n",
        "       8: very good, but solution is simple/old\n",
        "       10: innovative and technically sound\n",
        "       \n",
        "    7. how well did the team implement the solution in python? (10 points)\n",
        "       0: the code is not relevant to the solution proposed\n",
        "       2: the code is barely understandable, but not relevant\n",
        "       4: okay, the code is clear but incorrect\n",
        "       6: good, the code is correct, but with major errors\n",
        "       8: very good, the code is correct, but with minor errors\n",
        "      10: perfect \n",
        "   \n",
        "    -----------------------------------\n",
        "    The Results\n",
        "    -----------------------------------\n",
        "     8.  How well did the team present the results they found in the data? (10 points)\n",
        "       0: not clear\n",
        "       2: I can barely understand\n",
        "       4: okay, can be improved\n",
        "       6: good, but can be improved\n",
        "       8: very good\n",
        "      10: crystal clear\n",
        "       \n",
        "     9.  How do you think of the results they found in the data?  (5 points)\n",
        "       0: not clear\n",
        "       1: likely to be wrong\n",
        "       2: okay, maybe wrong\n",
        "       3: good, but can be improved\n",
        "       4: make sense, but not interesting\n",
        "       5: make sense and very interesting\n",
        "     \n",
        "    -----------------------------------\n",
        "    The Presentation\n",
        "    -----------------------------------\n",
        "    10. How all the different parts (data, problem, solution, result) fit together as a coherent story?  \n",
        "       0: they are irrelevant\n",
        "       1: I can barely understand how they are related to each other\n",
        "       2: okay, the problem is good, but the solution doesn't match well, or the problem is not solvable.\n",
        "       3: good, but the results don't make much sense in the context\n",
        "       4: very good fit, but not exciting (the storyline can be improved/polished)\n",
        "       5: a perfect story\n",
        "      \n",
        "    11. Did the presenter make good use of the 10 minutes for presentation?  \n",
        "       0: the team didn't present\n",
        "       1: bad, barely finished a small part of the talk\n",
        "       2: okay, barely finished most parts of the talk.\n",
        "       3: good, finished all parts of the talk, but some part is rushed\n",
        "       4: very good, but the allocation of time on different parts can be improved.\n",
        "       5: perfect timing and good use of time      \n",
        "\n",
        "    12. How well do you think of the presentation (overall quality)?  \n",
        "       0: the team didn't present\n",
        "       1: bad\n",
        "       2: okay\n",
        "       3: good\n",
        "       4: very good\n",
        "       5: perfect\n",
        "\n",
        "\n",
        "    -----------------------------------\n",
        "    Overall: \n",
        "    -----------------------------------\n",
        "    13. How many points out of the 100 do you give to this project in total?  Please don't worry about the absolute scores, we will rescale the final grading according to the performance of all teams in the class.\n",
        "    Total score:\n",
        "    \n",
        "    14. What are the strengths of this project? Briefly, list up to 3 strengths.\n",
        "       1: \n",
        "       2:\n",
        "       3:\n",
        "    \n",
        "    15. What are the weaknesses of this project? Briefly, list up to 3 weaknesses.\n",
        "       1:\n",
        "       2:\n",
        "       3:\n",
        "    \n",
        "    16. Detailed comments and suggestions. What suggestions do you have for this project to improve its quality further.\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "    ---------------------------------\n",
        "    Your Vote: \n",
        "    ---------------------------------\n",
        "    [Overall Quality] Between the two submissions that you are reviewing, which team would you vote for a better score?  (5 bonus points)\n",
        "        0: I vote the other team is better than this team\n",
        "        5: I vote this team is better than the other team \n",
        "        \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnulpQMQYCtf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}